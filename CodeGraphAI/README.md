# CodeGraphAI üîç

> An√°lise inteligente de procedures de banco de dados usando IA local

CodeGraphAI √© uma ferramenta Python que utiliza LLMs (Large Language Models) para analisar, mapear e visualizar depend√™ncias entre stored procedures de bancos de dados. Identifica relacionamentos, calcula complexidade e gera hierarquias de baixo at√© alto n√≠vel automaticamente.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)

## ‚ú® Funcionalidades

- ü§ñ **An√°lise com IA Local** - Usa modelos LLM (GPT-OSS-120B, Llama, etc.) para entender l√≥gica de neg√≥cio
- üìä **Mapeamento de Depend√™ncias** - Identifica chamadas entre procedures e acessos a tabelas
- üéØ **Hierarquia Bottom-Up** - Organiza procedures do n√≠vel mais baixo (sem depend√™ncias) at√© alto n√≠vel
- üìà **C√°lculo de Complexidade** - Score de 1-10 baseado em estrutura e l√≥gica do c√≥digo
- üé® **Visualiza√ß√µes Mermaid** - Gera diagramas interativos em markdown
- üíæ **An√°lise de Arquivos** - Trabalha com arquivos `.prc` locais (sem necessidade de conex√£o ao banco)
- üîÑ **Agn√≥stico de Banco** - Suporta Oracle, PostgreSQL, SQL Server e MySQL atrav√©s de adaptadores

## üöÄ Quick Start

### Instala√ß√£o

```bash
# Clone o reposit√≥rio
git clone https://github.com/seu-usuario/CodeGraphAI.git
cd CodeGraphAI

# Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Instale depend√™ncias
pip install -r requirements.txt

# Configure vari√°veis de ambiente
# Copie o arquivo de exemplo e preencha com suas credenciais
cp example.env .env
# ou
cp example.env environment.env
# Edite .env ou environment.env com suas credenciais reais
```

### Uso B√°sico

```python
from analyzer import LLMAnalyzer, ProcedureAnalyzer

# 1. Inicializa analisador com modelo local
llm = LLMAnalyzer(
    model_name="gpt-oss-120b",  # ou caminho local
    device="cuda"
)

# 2. Cria analisador de procedures
analyzer = ProcedureAnalyzer(llm)

# 3. Analisa procedures de arquivos .prc
analyzer.analyze_from_files("./procedures", extension="prc")

# 4. Exporta resultados
analyzer.export_results("analysis.json")
analyzer.export_mermaid_diagram("diagram.md")
analyzer.export_mermaid_hierarchy("hierarchy.md")
```

## üìã Requisitos

### Depend√™ncias Python

```txt
# Bancos de Dados (opcional - instale apenas os necess√°rios)
oracledb>=1.4.0              # Oracle
psycopg2-binary>=2.9.0       # PostgreSQL
pyodbc>=5.0.0                # SQL Server (via ODBC)
mysql-connector-python>=8.0.0  # MySQL

# LangChain - Framework para LLM
langchain>=0.1.0
langchain-community>=0.0.13

# Transformers e PyTorch - Modelos de IA
transformers>=4.35.0
torch>=2.0.0
accelerate>=0.25.0
bitsandbytes>=0.41.0         # Para quantiza√ß√£o 8-bit

# An√°lise de Grafos
networkx>=3.0

# Visualiza√ß√£o
matplotlib>=3.7.0

# CLI e Utilit√°rios
click>=8.0.0
tqdm>=4.65.0
python-dotenv>=1.0.0
```

### Hardware Recomendado

- **GPU**: NVIDIA com 24GB+ VRAM para modelos 120B (ou use quantiza√ß√£o)
- **CPU**: 16+ cores para processamento paralelo
- **RAM**: 32GB+ recomendado
- **Storage**: Depende do tamanho do modelo

## üìÇ Estrutura do Projeto

```
CodeGraphAI/
‚îú‚îÄ‚îÄ app/                    # M√≥dulos principais
‚îÇ   ‚îú‚îÄ‚îÄ core/              # Modelos e exce√ß√µes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py
‚îÇ   ‚îú‚îÄ‚îÄ io/                # Adaptadores de banco de dados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py        # Interface abstrata
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ factory.py     # Factory pattern
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ oracle_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ postgres_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mssql_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mysql_loader.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ file_loader.py
‚îÇ   ‚îî‚îÄ‚îÄ config/            # Configura√ß√£o
‚îÇ       ‚îî‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ analyzer.py            # Script principal (backward compatibility)
‚îú‚îÄ‚îÄ main.py                # CLI
‚îú‚îÄ‚îÄ config.py              # Wrapper de compatibilidade
‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias
‚îú‚îÄ‚îÄ requirements-dev.txt   # Depend√™ncias de desenvolvimento
‚îú‚îÄ‚îÄ README.md              # Este arquivo
‚îú‚îÄ‚îÄ procedures/            # Diret√≥rio com arquivos .prc
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ calc_saldo.prc
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ valida_cliente.prc
‚îÇ   ‚îî‚îÄ‚îÄ reports/
‚îÇ       ‚îî‚îÄ‚îÄ gera_relatorio.prc
‚îú‚îÄ‚îÄ output/                # Resultados gerados
‚îÇ   ‚îú‚îÄ‚îÄ analysis.json
‚îÇ   ‚îú‚îÄ‚îÄ diagram.md
‚îÇ   ‚îî‚îÄ‚îÄ hierarchy.md
‚îî‚îÄ‚îÄ tests/                 # Testes
    ‚îú‚îÄ‚îÄ io/               # Testes dos adaptadores
    ‚îî‚îÄ‚îÄ test_*.py
```

## üéØ Casos de Uso

### 1. An√°lise de Arquivos Locais (Recomendado)

```python
analyzer = ProcedureAnalyzer(llm)
analyzer.analyze_from_files("./procedures", "prc")
```

**Vantagens:**

- ‚úÖ Mais r√°pido (sem lat√™ncia de rede)
- ‚úÖ Funciona offline
- ‚úÖ Version√°vel com Git
- ‚úÖ Sem necessidade de credenciais

### 2. An√°lise Direta do Banco

```python
analyzer.analyze_from_database(
    user="usuario",
    password="senha",
    dsn="localhost:1521/ORCL",
    schema="MEU_SCHEMA"
)
```

**Quando usar:**

- Procedures n√£o est√£o em arquivos
- Precisa de metadados adicionais do banco
- An√°lise ad-hoc de ambiente de produ√ß√£o

### 3. An√°lise H√≠brida

```python
# Carrega de arquivos
analyzer.analyze_from_files("./procedures")

# Compara com banco para validar sincroniza√ß√£o
from analyzer import ProcedureLoader
db_procs = ProcedureLoader.from_database(user, password, dsn)

file_set = set(analyzer.procedures.keys())
db_set = set(db_procs.keys())

print(f"Apenas em arquivos: {file_set - db_set}")
print(f"Apenas no banco: {db_set - file_set}")
```

## üìä Tipos de Visualiza√ß√£o

### 1. Diagrama de Depend√™ncias

```python
analyzer.export_mermaid_diagram("diagram.md", max_nodes=50)
```

Gera grafo mostrando todas as depend√™ncias com cores por complexidade:

- üî¥ **Vermelho**: Alta complexidade (8-10)
- üü° **Amarelo**: M√©dia complexidade (5-7)
- üü¢ **Verde**: Baixa complexidade (1-4)

### 2. Hierarquia por N√≠veis

```python
analyzer.export_mermaid_hierarchy("hierarchy.md")
```

Organiza procedures em √°rvore hier√°rquica:

- **N√≠vel 0**: Procedures base (sem depend√™ncias)
- **N√≠vel 1**: Dependem apenas do n√≠vel 0
- **N√≠vel N**: Dependem at√© o n√≠vel N-1

### 3. Flowchart Detalhado

```python
analyzer.export_mermaid_flowchart("SCHEMA.PROCEDURE_NAME")
```

Mostra fluxo completo de uma procedure:

- Par√¢metros de entrada/sa√≠da
- Tabelas acessadas
- Procedures chamadas
- L√≥gica de neg√≥cio

## üîß Configura√ß√£o Avan√ßada

### Configura√ß√£o de Ambiente

CodeGraphAI usa vari√°veis de ambiente para configura√ß√£o. O projeto inclui um arquivo `example.env` como template.

**Primeiros passos:**

1. Copie o arquivo de exemplo:
```bash
cp example.env .env
# ou
cp example.env environment.env
```

2. Edite o arquivo copiado (`.env` ou `environment.env`) com suas credenciais reais:
   - API keys para OpenAI, Anthropic ou GenFactory
   - Credenciais de banco de dados
   - Caminhos de certificados SSL (se necess√°rio)

3. **IMPORTANTE**: Os arquivos `.env` e `environment.env` est√£o no `.gitignore` e n√£o ser√£o commitados. Nunca commite credenciais reais!

**Ordem de prioridade:**
- O sistema carrega primeiro `.env` (se existir)
- Se `.env` n√£o existir, carrega `environment.env`
- Se nenhum existir, usa valores padr√£o

**Arquivos:**
- `example.env`: Template versionado no Git (sem credenciais)
- `.env`: Suas credenciais locais (n√£o versionado)
- `environment.env`: Suas credenciais locais (n√£o versionado)

### Suporte a M√∫ltiplos Bancos de Dados

CodeGraphAI suporta m√∫ltiplos bancos de dados atrav√©s de adaptadores:

- **Oracle**: Usa `oracledb` (padr√£o para backward compatibility)
- **PostgreSQL**: Usa `psycopg2-binary`
- **SQL Server**: Usa `pyodbc` ou `pymssql`
- **MySQL**: Usa `mysql-connector-python` ou `pymysql`

**Instala√ß√£o de drivers:**
```bash
# Instalar apenas o necess√°rio
pip install oracledb>=1.4.0                    # Oracle
pip install psycopg2-binary>=2.9.0              # PostgreSQL
pip install pyodbc>=5.0.0                       # SQL Server
pip install mysql-connector-python>=8.0.0       # MySQL
```

**Uso via CLI:**
```bash
# Oracle (padr√£o)
python main.py analyze-db --user user --password pass --dsn localhost:1521/ORCL

# PostgreSQL
python main.py analyze-db --db-type postgresql --user user --password pass \
    --host localhost --port 5432 --database meu_banco

# SQL Server
python main.py analyze-db --db-type mssql --user user --password pass \
    --host localhost --port 1433 --database meu_banco

# MySQL
python main.py analyze-db --db-type mysql --user user --password pass \
    --host localhost --port 3306 --database meu_banco
```

**Vari√°veis de ambiente:**
```bash
CODEGRAPHAI_DB_TYPE=postgresql
CODEGRAPHAI_DB_HOST=localhost
CODEGRAPHAI_DB_PORT=5432
CODEGRAPHAI_DB_NAME=meu_banco
CODEGRAPHAI_DB_USER=usuario
CODEGRAPHAI_DB_PASSWORD=senha
CODEGRAPHAI_DB_SCHEMA=public
```

### Modelos LLM Suportados

#### Modo Local (HuggingFace)

```python
# Modelos Locais
llm = LLMAnalyzer(model_name="gpt-oss-120b", device="cuda")
llm = LLMAnalyzer(model_name="meta-llama/Llama-2-70b-hf", device="cuda")
llm = LLMAnalyzer(model_name="mistralai/Mixtral-8x7B-v0.1", device="cuda")

# Caminho local
llm = LLMAnalyzer(model_name="/path/to/local/model", device="cuda")

# CPU (mais lento)
llm = LLMAnalyzer(model_name="gpt-oss-120b", device="cpu")
```

#### Modo API (GenFactory - BNP Paribas)

CodeGraphAI suporta LLM via API GenFactory, permitindo usar modelos remotos sem necessidade de GPU local.

**Configura√ß√£o:**

1. Copie `example.env` para `.env` ou `environment.env` e configure:
```bash
# Copie o template
cp example.env .env
# ou
cp example.env environment.env

# Edite o arquivo com suas credenciais
CODEGRAPHAI_LLM_MODE=api
CODEGRAPHAI_LLM_PROVIDER=genfactory_llama70b  # ou genfactory_codestral, genfactory_gptoss120b

# Provider: Llama 70B
CODEGRAPHAI_GENFACTORY_LLAMA70B_BASE_URL=https://genfactory-ai.analytics.cib.echonet/genai/api/v2
CODEGRAPHAI_GENFACTORY_LLAMA70B_MODEL=meta-llama-3.3-70b-instruct
CODEGRAPHAI_GENFACTORY_LLAMA70B_AUTHORIZATION_TOKEN=seu_token_aqui
CODEGRAPHAI_GENFACTORY_LLAMA70B_TIMEOUT=20000
CODEGRAPHAI_GENFACTORY_LLAMA70B_VERIFY_SSL=true
CODEGRAPHAI_GENFACTORY_LLAMA70B_CA_BUNDLE_PATH=caminho/cert1.cer;caminho/cert2.cer
```

2. Use no c√≥digo:
```python
from analyzer import LLMAnalyzer
from config import get_config

config = get_config()
llm = LLMAnalyzer(llm_mode='api', config=config)
```

**Providers Dispon√≠veis:**
- `genfactory_llama70b`: Meta Llama 3.3 70B Instruct
- `genfactory_codestral`: Codestral Latest
- `genfactory_gptoss120b`: GPT-OSS-120B

**Vantagens do Modo API:**
- N√£o requer GPU local
- N√£o requer download de modelos grandes
- Acesso a modelos atualizados
- Escalabilidade autom√°tica

#### Modo API (OpenAI)

CodeGraphAI suporta modelos OpenAI via API, incluindo os modelos mais recentes (gpt-5.1, gpt-5-mini, gpt-5-nano).

**Configura√ß√£o:**

1. Copie `example.env` para `.env` ou `environment.env` e configure:
```bash
# Copie o template
cp example.env .env
# ou
cp example.env environment.env

# Edite o arquivo com suas credenciais
CODEGRAPHAI_LLM_MODE=api
CODEGRAPHAI_LLM_PROVIDER=openai

# OpenAI Configuration
CODEGRAPHAI_OPENAI_API_KEY=sk-...
CODEGRAPHAI_OPENAI_MODEL=gpt-5.1  # ou gpt-5-mini, gpt-5-nano
CODEGRAPHAI_OPENAI_BASE_URL=https://api.openai.com/v1  # Opcional para Azure OpenAI
CODEGRAPHAI_OPENAI_TIMEOUT=60
CODEGRAPHAI_OPENAI_TEMPERATURE=0.3
CODEGRAPHAI_OPENAI_MAX_TOKENS=4000
```

2. Use no c√≥digo:
```python
from analyzer import LLMAnalyzer
from config import get_config

config = get_config()
llm = LLMAnalyzer(llm_mode='api', config=config)
```

**Modelos Dispon√≠veis:**
- `gpt-5.1`: Modelo mais recente e mais capaz (padr√£o)
- `gpt-5-mini`: Vers√£o mais r√°pida e econ√¥mica, ideal para tarefas simples
- `gpt-5-nano`: Vers√£o mais compacta, para uso em larga escala

**Quando usar cada modelo:**
- **gpt-5.1**: Para an√°lises complexas que requerem maior capacidade de racioc√≠nio
- **gpt-5-mini**: Para an√°lises r√°pidas e tarefas simples
- **gpt-5-nano**: Para processamento em larga escala com muitos procedures

**Azure OpenAI:**
Para usar Azure OpenAI, configure `CODEGRAPHAI_OPENAI_BASE_URL` com o endpoint do Azure:
```bash
CODEGRAPHAI_OPENAI_BASE_URL=https://seu-recurso.openai.azure.com/
```

**Refer√™ncia:** [LangChain OpenAI Documentation](https://docs.langchain.com/oss/python/langchain/models)

#### Modo API (Anthropic Claude)

CodeGraphAI suporta Anthropic Claude via API, incluindo o modelo mais recente Claude Sonnet 4.5.

**Configura√ß√£o:**

1. Copie `example.env` para `.env` ou `environment.env` e configure:
```bash
# Copie o template
cp example.env .env
# ou
cp example.env environment.env

# Edite o arquivo com suas credenciais
CODEGRAPHAI_LLM_MODE=api
CODEGRAPHAI_LLM_PROVIDER=anthropic

# Anthropic Claude Configuration
CODEGRAPHAI_ANTHROPIC_API_KEY=sk-ant-...
CODEGRAPHAI_ANTHROPIC_MODEL=claude-sonnet-4-5-20250929
CODEGRAPHAI_ANTHROPIC_TIMEOUT=60
CODEGRAPHAI_ANTHROPIC_TEMPERATURE=0.3
CODEGRAPHAI_ANTHROPIC_MAX_TOKENS=4000
```

2. Use no c√≥digo:
```python
from analyzer import LLMAnalyzer
from config import get_config

config = get_config()
llm = LLMAnalyzer(llm_mode='api', config=config)
```

**Modelo Dispon√≠vel:**
- `claude-sonnet-4-5-20250929`: Claude Sonnet 4.5 (modelo mais recente, padr√£o)
- `claude-sonnet-4-5`: Alias para o modelo mais recente

**Vantagens do Claude Sonnet 4.5:**
- Excelente para an√°lise de c√≥digo e racioc√≠nio complexo
- Suporte a contextos longos
- Alta qualidade em tarefas de an√°lise e extra√ß√£o

**Refer√™ncia:** [LangChain Anthropic Documentation](https://docs.langchain.com/oss/python/langchain/models)

### Quantiza√ß√£o para Economia de Mem√≥ria

Por padr√£o, usa quantiza√ß√£o 8-bit. Para modelos menores:

```python
# Desabilitar quantiza√ß√£o (requer mais VRAM)
# Edite em analyzer.py:
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",
    load_in_8bit=False,  # Altere aqui
    torch_dtype="auto"
)
```

### Ajuste de Prompts

Edite os templates em `LLMAnalyzer._setup_prompts()` para customizar an√°lises:

```python
self.business_logic_prompt = PromptTemplate(
    input_variables=["code", "proc_name"],
    template="""Seu prompt customizado aqui..."""
)
```

## üìà Exemplo de Output

### JSON (analysis.json)

```json
{
  "procedures": {
    "CALC_SALDO": {
      "name": "CALC_SALDO",
      "schema": "FINANCEIRO",
      "complexity_score": 7,
      "dependencies_level": 0,
      "called_procedures": ["VALIDA_CONTA", "BUSCA_HISTORICO"],
      "called_tables": ["CONTAS", "TRANSACOES"],
      "business_logic": "Calcula saldo atual de uma conta..."
    }
  },
  "hierarchy": {
    "0": ["CALC_SALDO", "VALIDA_CONTA"],
    "1": ["GERA_RELATORIO"],
    "2": ["EXPORTA_DADOS"]
  },
  "statistics": {
    "total_procedures": 45,
    "avg_complexity": 5.8,
    "max_dependency_level": 4
  }
}
```

### Mermaid Diagram

```mermaid
graph TD
    CALC_SALDO["CALC_SALDO\n[N√≠vel 0, Complex: 7]"]:::medium
    VALIDA_CONTA["VALIDA_CONTA\n[N√≠vel 0, Complex: 3]"]:::low
    GERA_RELATORIO["GERA_RELATORIO\n[N√≠vel 1, Complex: 9]"]:::high

    GERA_RELATORIO --> CALC_SALDO
    GERA_RELATORIO --> VALIDA_CONTA

    classDef high fill:#ff6b6b,stroke:#c92a2a,color:#fff
    classDef medium fill:#ffd93d,stroke:#f59f00,color:#000
    classDef low fill:#51cf66,stroke:#2b8a3e,color:#000
```

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üó∫
