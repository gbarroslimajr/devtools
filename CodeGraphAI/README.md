# CodeGraphAI üîç

> An√°lise inteligente de procedures e tabelas de banco de dados usando IA local

CodeGraphAI √© uma ferramenta Python que utiliza LLMs (Large Language Models) para analisar, mapear e visualizar depend√™ncias entre stored procedures e tabelas de bancos de dados. Identifica relacionamentos, calcula complexidade e gera hierarquias de baixo at√© alto n√≠vel automaticamente. Permite escolher entre analisar apenas procedures, apenas tabelas ou ambos atrav√©s da flag `--analysis-type`.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)

## ‚ú® Funcionalidades

- ü§ñ **An√°lise com IA Local** - Usa modelos LLM (GPT-OSS-120B, Llama, etc.) para entender l√≥gica de neg√≥cio
- üìä **Mapeamento de Depend√™ncias** - Identifica chamadas entre procedures e acessos a tabelas
- üóÑÔ∏è **An√°lise de Tabelas** - Analisa estrutura de tabelas (DDL, relacionamentos, √≠ndices, foreign keys)
- üéØ **Hierarquia Bottom-Up** - Organiza procedures e tabelas do n√≠vel mais baixo (sem depend√™ncias) at√© alto n√≠vel
- üìà **C√°lculo de Complexidade** - Score de 1-10 baseado em estrutura e l√≥gica do c√≥digo
- üé® **Visualiza√ß√µes Mermaid** - Gera diagramas interativos em markdown (procedures e tabelas)
- üíæ **An√°lise de Arquivos** - Trabalha com arquivos `.prc` locais (sem necessidade de conex√£o ao banco)
- üîÑ **Agn√≥stico de Banco** - Suporta Oracle, PostgreSQL, SQL Server e MySQL atrav√©s de adaptadores
- üéõÔ∏è **An√°lise Flex√≠vel** - Escolha entre analisar tabelas, procedures ou ambos com flag `--analysis-type`

## üöÄ Quick Start

### Instala√ß√£o

```bash
# Clone o reposit√≥rio
git clone https://github.com/seu-usuario/CodeGraphAI.git
cd CodeGraphAI

# Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Instale depend√™ncias
pip install -r requirements.txt

# Configure vari√°veis de ambiente
# Copie o arquivo de exemplo e preencha com suas credenciais
cp example.env .env
# ou
cp example.env environment.env
# Edite .env ou environment.env com suas credenciais reais
```

### Uso B√°sico

#### Via CLI (Recomendado)

```bash
# An√°lise de tabelas (PostgreSQL)
python main.py analyze --analysis-type=tables \
    --db-type postgresql \
    --user postgres --password senha \
    --host localhost --port 5432 \
    --database meu_banco --schema public

# An√°lise de procedures (Oracle)
python main.py analyze --analysis-type=procedures \
    --db-type oracle \
    --user usuario --password senha \
    --dsn localhost:1521/ORCL --schema MEU_SCHEMA

# An√°lise de ambos (padr√£o)
python main.py analyze --analysis-type=both \
    --db-type postgresql \
    --user postgres --password senha \
    --host localhost --port 5432 \
    --database meu_banco --schema public
```

#### Via Python

```python
from analyzer import LLMAnalyzer, ProcedureAnalyzer

# 1. Inicializa analisador com modelo local
llm = LLMAnalyzer(
    model_name="gpt-oss-120b",  # ou caminho local
    device="cuda"
)

# 2. Cria analisador de procedures
analyzer = ProcedureAnalyzer(llm)

# 3. Analisa procedures de arquivos .prc
analyzer.analyze_from_files("./procedures", extension="prc")

# 4. Exporta resultados
analyzer.export_results("analysis.json")
analyzer.export_mermaid_diagram("diagram.md")
analyzer.export_mermaid_hierarchy("hierarchy.md")
```

## üìã Requisitos

### Depend√™ncias Python

```txt
# Bancos de Dados (opcional - instale apenas os necess√°rios)
oracledb>=1.4.0              # Oracle
psycopg2-binary>=2.9.0       # PostgreSQL
pyodbc>=5.0.0                # SQL Server (via ODBC)
mysql-connector-python>=8.0.0  # MySQL

# LangChain - Framework para LLM
langchain>=0.1.0
langchain-community>=0.0.13

# Transformers e PyTorch - Modelos de IA
transformers>=4.35.0
torch>=2.0.0
accelerate>=0.25.0
bitsandbytes>=0.41.0         # Para quantiza√ß√£o 8-bit

# An√°lise de Grafos
networkx>=3.0

# Visualiza√ß√£o
matplotlib>=3.7.0

# CLI e Utilit√°rios
click>=8.0.0
tqdm>=4.65.0
python-dotenv>=1.0.0
```

### Hardware Recomendado

- **GPU**: NVIDIA com 24GB+ VRAM para modelos 120B (ou use quantiza√ß√£o)
- **CPU**: 16+ cores para processamento paralelo
- **RAM**: 32GB+ recomendado
- **Storage**: Depende do tamanho do modelo

## üìÇ Estrutura do Projeto

```
CodeGraphAI/
‚îú‚îÄ‚îÄ app/                    # M√≥dulos principais
‚îÇ   ‚îú‚îÄ‚îÄ core/              # Modelos e exce√ß√µes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py      # ProcedureInfo, TableInfo, etc.
‚îÇ   ‚îú‚îÄ‚îÄ io/                # Adaptadores de banco de dados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py        # Interface abstrata (procedures)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ table_base.py  # Interface abstrata (tabelas)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ factory.py     # Factory pattern (procedures)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ table_factory.py # Factory pattern (tabelas)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ oracle_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ oracle_table_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ postgres_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ postgres_table_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mssql_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mssql_table_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mysql_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mysql_table_loader.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ file_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ llm/               # Integra√ß√£o com LLMs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ langchain_wrapper.py
‚îÇ   ‚îî‚îÄ‚îÄ config/            # Configura√ß√£o
‚îÇ       ‚îî‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ analyzer.py            # LLMAnalyzer e ProcedureAnalyzer
‚îú‚îÄ‚îÄ table_analyzer.py      # TableAnalyzer
‚îú‚îÄ‚îÄ main.py                # CLI (comando analyze unificado)
‚îú‚îÄ‚îÄ config.py              # Wrapper de compatibilidade
‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias
‚îú‚îÄ‚îÄ requirements-dev.txt   # Depend√™ncias de desenvolvimento
‚îú‚îÄ‚îÄ README.md              # Este arquivo
‚îú‚îÄ‚îÄ procedures/            # Diret√≥rio com arquivos .prc
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ calc_saldo.prc
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ valida_cliente.prc
‚îÇ   ‚îî‚îÄ‚îÄ reports/
‚îÇ       ‚îî‚îÄ‚îÄ gera_relatorio.prc
‚îú‚îÄ‚îÄ output/                # Resultados gerados
‚îÇ   ‚îú‚îÄ‚îÄ procedure_analysis.json
‚îÇ   ‚îú‚îÄ‚îÄ table_analysis.json
‚îÇ   ‚îú‚îÄ‚îÄ dependency_graph.png
‚îÇ   ‚îú‚îÄ‚îÄ relationship_graph.png
‚îÇ   ‚îú‚îÄ‚îÄ procedure_diagram.md
‚îÇ   ‚îú‚îÄ‚îÄ table_diagram.md
‚îÇ   ‚îî‚îÄ‚îÄ *_hierarchy.md
‚îî‚îÄ‚îÄ tests/                 # Testes
    ‚îú‚îÄ‚îÄ io/               # Testes dos adaptadores
    ‚îÇ   ‚îú‚îÄ‚îÄ test_table_loaders.py
    ‚îÇ   ‚îî‚îÄ‚îÄ test_*.py
    ‚îî‚îÄ‚îÄ test_table_analyzer.py
```

## üéØ Casos de Uso

### 1. An√°lise de Arquivos Locais (Recomendado)

```python
analyzer = ProcedureAnalyzer(llm)
analyzer.analyze_from_files("./procedures", "prc")
```

**Vantagens:**

- ‚úÖ Mais r√°pido (sem lat√™ncia de rede)
- ‚úÖ Funciona offline
- ‚úÖ Version√°vel com Git
- ‚úÖ Sem necessidade de credenciais

### 2. An√°lise Direta do Banco

**Via CLI (Recomendado):**
```bash
# An√°lise de procedures
python main.py analyze --analysis-type=procedures \
    --user usuario --password senha --host localhost \
    --database meu_banco --schema MEU_SCHEMA

# An√°lise de tabelas
python main.py analyze --analysis-type=tables \
    --user usuario --password senha --host localhost \
    --database meu_banco --schema MEU_SCHEMA

# An√°lise de ambos (padr√£o)
python main.py analyze --analysis-type=both \
    --user usuario --password senha --host localhost \
    --database meu_banco --schema MEU_SCHEMA
```

**Nota:** Veja a se√ß√£o [Comandos CLI](#-comandos-cli) abaixo para exemplos completos com todos os argumentos dispon√≠veis.

**Via Python:**
```python
# Procedures
analyzer = ProcedureAnalyzer(llm)
analyzer.analyze_from_database(
    user="usuario",
    password="senha",
    dsn="localhost:1521/ORCL",
    schema="MEU_SCHEMA"
)

# Tabelas
from table_analyzer import TableAnalyzer
table_analyzer = TableAnalyzer(llm)
table_analyzer.analyze_from_database(
    user="usuario",
    password="senha",
    dsn="localhost",
    schema="MEU_SCHEMA",
    db_type="postgresql",
    database="meu_banco",
    port=5432
)
```

**Quando usar:**

- Procedures n√£o est√£o em arquivos
- Precisa de metadados adicionais do banco
- An√°lise ad-hoc de ambiente de produ√ß√£o
- An√°lise de estrutura de tabelas (DDL, relacionamentos, √≠ndices)

### 3. An√°lise H√≠brida

```python
# Carrega de arquivos
analyzer.analyze_from_files("./procedures")

# Compara com banco para validar sincroniza√ß√£o
from analyzer import ProcedureLoader
db_procs = ProcedureLoader.from_database(user, password, dsn)

file_set = set(analyzer.procedures.keys())
db_set = set(db_procs.keys())

print(f"Apenas em arquivos: {file_set - db_set}")
print(f"Apenas no banco: {db_set - file_set}")
```

### 4. An√°lise de Tabelas

**Via CLI:**
```bash
# Analisar apenas tabelas
python main.py analyze --analysis-type=tables \
    --db-type postgresql --user user --password pass \
    --host localhost --port 5432 --database meu_banco \
    --schema public

# Analisar tabelas e procedures juntos
python main.py analyze --analysis-type=both \
    --db-type postgresql --user user --password pass \
    --host localhost --port 5432 --database meu_banco \
    --schema public
```

**O que √© analisado:**
- Estrutura completa (DDL)
- Colunas com tipos, constraints, defaults
- √çndices (B-tree, Hash, etc.)
- Foreign keys e relacionamentos
- Estat√≠sticas (row count, table size)
- Prop√≥sito de neg√≥cio (via LLM)
- Complexidade baseada em estrutura

**Exporta√ß√£o:**
- `table_analysis.json`: Metadados completos
- `relationship_graph.png`: Grafo de relacionamentos via FKs
- `table_diagram.md`: Diagrama ER em Mermaid
- `table_hierarchy.md`: Hierarquia por n√≠veis de depend√™ncia

## üìä Tipos de Visualiza√ß√£o

### 1. Diagrama de Depend√™ncias (Procedures)

```python
analyzer.export_mermaid_diagram("diagram.md", max_nodes=50)
```

Gera grafo mostrando todas as depend√™ncias entre procedures com cores por complexidade:

- üî¥ **Vermelho**: Alta complexidade (8-10)
- üü° **Amarelo**: M√©dia complexidade (5-7)
- üü¢ **Verde**: Baixa complexidade (1-4)

### 2. Hierarquia por N√≠veis (Procedures)

```python
analyzer.export_mermaid_hierarchy("hierarchy.md")
```

Organiza procedures em √°rvore hier√°rquica:

- **N√≠vel 0**: Procedures base (sem depend√™ncias)
- **N√≠vel 1**: Dependem apenas do n√≠vel 0
- **N√≠vel N**: Dependem at√© o n√≠vel N-1

### 3. Flowchart Detalhado (Procedures)

```python
analyzer.export_mermaid_flowchart("SCHEMA.PROCEDURE_NAME")
```

Mostra fluxo completo de uma procedure:

- Par√¢metros de entrada/sa√≠da
- Tabelas acessadas
- Procedures chamadas
- L√≥gica de neg√≥cio

### 4. Diagrama ER (Tabelas)

```python
table_analyzer.export_mermaid_diagram("table_diagram.md")
```

Gera diagrama entidade-relacionamento mostrando:

- Tabelas e suas colunas
- Foreign keys e relacionamentos
- √çndices e constraints
- Complexidade por tabela

### 5. Hierarquia de Relacionamentos (Tabelas)

```python
table_analyzer.export_mermaid_hierarchy("table_hierarchy.md")
```

Organiza tabelas por n√≠veis de depend√™ncia baseado em foreign keys:

- **N√≠vel 0**: Tabelas base (sem FKs ou apenas FKs externas)
- **N√≠vel 1**: Dependem apenas do n√≠vel 0
- **N√≠vel N**: Dependem at√© o n√≠vel N-1

### 6. Grafo de Relacionamentos (Tabelas)

```python
table_analyzer.visualize_relationships("relationship_graph.png")
```

Gera grafo visual (PNG) mostrando todas as rela√ß√µes entre tabelas via foreign keys.

## üîß Configura√ß√£o Avan√ßada

### Configura√ß√£o de Ambiente

CodeGraphAI usa vari√°veis de ambiente para configura√ß√£o. O projeto inclui um arquivo `example.env` como template.

**Primeiros passos:**

1. Copie o arquivo de exemplo:
```bash
cp example.env .env
# ou
cp example.env environment.env
```

2. Edite o arquivo copiado (`.env` ou `environment.env`) com suas credenciais reais:
   - API keys para OpenAI, Anthropic ou GenFactory
   - Credenciais de banco de dados
   - Caminhos de certificados SSL (se necess√°rio)

3. **IMPORTANTE**: Os arquivos `.env` e `environment.env` est√£o no `.gitignore` e n√£o ser√£o commitados. Nunca commite credenciais reais!

**Ordem de prioridade:**
- O sistema carrega primeiro `.env` (se existir)
- Se `.env` n√£o existir, carrega `environment.env`
- Se nenhum existir, usa valores padr√£o

**Arquivos:**
- `example.env`: Template versionado no Git (sem credenciais)
- `.env`: Suas credenciais locais (n√£o versionado)
- `environment.env`: Suas credenciais locais (n√£o versionado)

### Suporte a M√∫ltiplos Bancos de Dados

CodeGraphAI suporta m√∫ltiplos bancos de dados atrav√©s de adaptadores:

- **Oracle**: Usa `oracledb` (padr√£o para backward compatibility)
- **PostgreSQL**: Usa `psycopg2-binary`
- **SQL Server**: Usa `pyodbc` ou `pymssql`
- **MySQL**: Usa `mysql-connector-python` ou `pymysql`

**Instala√ß√£o de drivers:**
```bash
# Instalar apenas o necess√°rio
pip install oracledb>=1.4.0                    # Oracle
pip install psycopg2-binary>=2.9.0              # PostgreSQL
pip install pyodbc>=5.0.0                       # SQL Server
pip install mysql-connector-python>=8.0.0       # MySQL
```

**Uso via CLI:**

O comando `analyze` permite escolher o tipo de an√°lise atrav√©s da flag `--analysis-type`:

- `tables`: Analisa apenas tabelas (DDL, relacionamentos, √≠ndices)
- `procedures`: Analisa apenas stored procedures
- `both`: Analisa ambos (padr√£o)

```bash
# An√°lise de procedures apenas (Oracle)
python main.py analyze --analysis-type=procedures --user user --password pass \
    --dsn localhost:1521/ORCL

# An√°lise de tabelas apenas (PostgreSQL)
python main.py analyze --analysis-type=tables --db-type postgresql \
    --user user --password pass --host localhost --port 5432 \
    --database meu_banco --schema public

# An√°lise de ambos (padr√£o) - PostgreSQL
python main.py analyze --analysis-type=both --db-type postgresql \
    --user user --password pass --host localhost --port 5432 \
    --database meu_banco --schema public

# SQL Server - An√°lise de procedures
python main.py analyze --analysis-type=procedures --db-type mssql \
    --user user --password pass --host localhost --port 1433 \
    --database meu_banco

# MySQL - An√°lise de tabelas
python main.py analyze --analysis-type=tables --db-type mysql \
    --user user --password pass --host localhost --port 3306 \
    --database meu_banco
```

**Op√ß√µes de exporta√ß√£o:**
```bash
# Exportar apenas JSON
python main.py analyze --analysis-type=both --export-json \
    --user user --password pass --host localhost --database meu_banco

# Exportar JSON, PNG e Mermaid
python main.py analyze --analysis-type=both --export-json --export-png --export-mermaid \
    --user user --password pass --host localhost --database meu_banco

# Quando analysis-type=both, arquivos s√£o exportados separadamente:
# - procedure_analysis.json / table_analysis.json
# - dependency_graph.png / relationship_graph.png
# - procedure_diagram.md / table_diagram.md
```

### Dry-Run Mode

O modo dry-run permite validar configura√ß√µes e par√¢metros sem executar an√°lises reais, √∫til para:
- Validar configura√ß√µes antes de executar an√°lises
- Verificar par√¢metros sem custos de API ou conex√µes de banco
- Testar configura√ß√µes em ambientes de desenvolvimento
- Integra√ß√£o em pipelines CI/CD

**Uso:**
```bash
# Validar configura√ß√£o antes de executar an√°lise de banco
python main.py analyze --dry-run --analysis-type=both \
    --user postgres --password changeme --host localhost \
    --database postgres --schema public

# Validar an√°lise de arquivos
python main.py analyze-files --dry-run --directory ./procedures
```

**O que √© validado:**
- ‚úÖ Configura√ß√£o de banco de dados (tipo, par√¢metros, porta)
- ‚úÖ Configura√ß√£o LLM (modo, provider, API keys)
- ‚úÖ Par√¢metros de an√°lise (tipo, limit, output directory)
- ‚úÖ Permiss√µes de escrita no diret√≥rio de sa√≠da
- ‚úÖ Exist√™ncia de arquivos .prc (para analyze-files)

**Formato de sa√≠da:**
```
üîç DRY-RUN MODE - Valida√ß√£o de Configura√ß√£o
==========================================

‚úÖ Informa√ß√µes:
   - Tipo de banco: postgresql
   - Host: localhost:5432
   - Database: postgres
   - Schema: public
   - Modo LLM: api
   - Provider: anthropic
   - Tipo de an√°lise: both

‚ö†Ô∏è  Avisos:
   - API key n√£o verificada (dry-run n√£o valida autentica√ß√£o)

üìä Estimativas:
   - Limit: 10 entidades

‚úÖ Valida√ß√£o conclu√≠da com sucesso!
   Execute sem --dry-run para realizar a an√°lise.
```

**C√≥digos de sa√≠da:**
- `0`: Valida√ß√£o bem-sucedida (sem erros)
- `1`: Valida√ß√£o falhou (erros encontrados)

### Teste de Conex√£o

O comando `test-connection` testa apenas a conectividade com banco de dados usando queries simples (SELECT 1), sem carregar procedures ou tabelas. √ötil para:
- Verificar se credenciais est√£o corretas
- Testar conectividade de rede
- Validar configura√ß√£o antes de executar an√°lises
- Troubleshooting de conex√£o

**Uso:**
```bash
# Testar conex√£o PostgreSQL
python main.py test-connection --db-type postgresql \
    --user postgres --password changeme \
    --host localhost --port 5432 --database postgres

# Testar conex√£o Oracle
python main.py test-connection --db-type oracle \
    --user user --password pass --dsn localhost:1521/ORCL

# Testar conex√£o SQL Server
python main.py test-connection --db-type mssql \
    --user user --password pass \
    --host localhost --port 1433 --database mydb

# Testar conex√£o MySQL
python main.py test-connection --db-type mysql \
    --user user --password pass \
    --host localhost --port 3306 --database mydb
```

**Formato de sa√≠da:**
```
Testando conex√£o com POSTGRESQL (localhost:5432)...
‚úÖ Conex√£o bem-sucedida!
   Tipo: POSTGRESQL
   Host: localhost:5432
   Database: postgres
   Usu√°rio: postgres
```

**Diferen√ßas entre comandos:**
- `test-connection`: Testa apenas conectividade (r√°pido, query simples)
- `analyze --dry-run`: Valida configura√ß√£o sem conectar (muito r√°pido, sem I/O)
- `analyze`: Executa an√°lise completa (lento, carrega dados e chama LLM)

**Troubleshooting:**
- Erro de autentica√ß√£o: Verifique usu√°rio e senha
- Erro de rede: Verifique host e porta
- Database n√£o encontrado: Verifique nome do banco
- Driver n√£o instalado: Instale o driver apropriado (psycopg2, oracledb, etc.)

**Vari√°veis de ambiente:**
```bash
CODEGRAPHAI_DB_TYPE=postgresql
CODEGRAPHAI_DB_HOST=localhost
CODEGRAPHAI_DB_PORT=5432
CODEGRAPHAI_DB_NAME=meu_banco
CODEGRAPHAI_DB_USER=usuario
CODEGRAPHAI_DB_PASSWORD=senha
CODEGRAPHAI_DB_SCHEMA=public
```

### Modelos LLM Suportados

#### Modo Local (HuggingFace)

```python
# Modelos Locais
llm = LLMAnalyzer(model_name="gpt-oss-120b", device="cuda")
llm = LLMAnalyzer(model_name="meta-llama/Llama-2-70b-hf", device="cuda")
llm = LLMAnalyzer(model_name="mistralai/Mixtral-8x7B-v0.1", device="cuda")

# Caminho local
llm = LLMAnalyzer(model_name="/path/to/local/model", device="cuda")

# CPU (mais lento)
llm = LLMAnalyzer(model_name="gpt-oss-120b", device="cpu")
```

#### Modo API (GenFactory)

CodeGraphAI suporta LLM via API GenFactory, permitindo usar modelos remotos sem necessidade de GPU local.

**Configura√ß√£o:**

1. Copie `example.env` para `.env` ou `environment.env` e configure:
```bash
# Copie o template
cp example.env .env
# ou
cp example.env environment.env

# Edite o arquivo com suas credenciais
CODEGRAPHAI_LLM_MODE=api
CODEGRAPHAI_LLM_PROVIDER=genfactory_llama70b  # ou genfactory_codestral, genfactory_gptoss120b

# Provider: Llama 70B
CODEGRAPHAI_GENFACTORY_LLAMA70B_BASE_URL=https://genfactory-ai.analytics.cib.echonet/genai/api/v2
CODEGRAPHAI_GENFACTORY_LLAMA70B_MODEL=meta-llama-3.3-70b-instruct
CODEGRAPHAI_GENFACTORY_LLAMA70B_AUTHORIZATION_TOKEN=seu_token_aqui
CODEGRAPHAI_GENFACTORY_LLAMA70B_TIMEOUT=20000
CODEGRAPHAI_GENFACTORY_LLAMA70B_VERIFY_SSL=true
CODEGRAPHAI_GENFACTORY_LLAMA70B_CA_BUNDLE_PATH=caminho/cert1.cer;caminho/cert2.cer
```

2. Use no c√≥digo:
```python
from analyzer import LLMAnalyzer
from config import get_config

config = get_config()
llm = LLMAnalyzer(llm_mode='api', config=config)
```

**Providers Dispon√≠veis:**
- `genfactory_llama70b`: Meta Llama 3.3 70B Instruct
- `genfactory_codestral`: Codestral Latest
- `genfactory_gptoss120b`: GPT-OSS-120B

**Vantagens do Modo API:**
- N√£o requer GPU local
- N√£o requer download de modelos grandes
- Acesso a modelos atualizados
- Escalabilidade autom√°tica

#### Modo API (OpenAI)

CodeGraphAI suporta modelos OpenAI via API, incluindo os modelos mais recentes (gpt-5.1, gpt-5-mini, gpt-5-nano).

**Configura√ß√£o:**

1. Copie `example.env` para `.env` ou `environment.env` e configure:
```bash
# Copie o template
cp example.env .env
# ou
cp example.env environment.env

# Edite o arquivo com suas credenciais
CODEGRAPHAI_LLM_MODE=api
CODEGRAPHAI_LLM_PROVIDER=openai

# OpenAI Configuration
CODEGRAPHAI_OPENAI_API_KEY=sk-...
CODEGRAPHAI_OPENAI_MODEL=gpt-5.1  # ou gpt-5-mini, gpt-5-nano
CODEGRAPHAI_OPENAI_BASE_URL=https://api.openai.com/v1  # Opcional para Azure OpenAI
CODEGRAPHAI_OPENAI_TIMEOUT=60
CODEGRAPHAI_OPENAI_TEMPERATURE=0.3
CODEGRAPHAI_OPENAI_MAX_TOKENS=4000
```

2. Use no c√≥digo:
```python
from analyzer import LLMAnalyzer
from config import get_config

config = get_config()
llm = LLMAnalyzer(llm_mode='api', config=config)
```

**Modelos Dispon√≠veis:**
- `gpt-5.1`: Modelo mais recente e mais capaz (padr√£o)
- `gpt-5-mini`: Vers√£o mais r√°pida e econ√¥mica, ideal para tarefas simples
- `gpt-5-nano`: Vers√£o mais compacta, para uso em larga escala

**Quando usar cada modelo:**
- **gpt-5.1**: Para an√°lises complexas que requerem maior capacidade de racioc√≠nio
- **gpt-5-mini**: Para an√°lises r√°pidas e tarefas simples
- **gpt-5-nano**: Para processamento em larga escala com muitos procedures

**Azure OpenAI:**
Para usar Azure OpenAI, configure `CODEGRAPHAI_OPENAI_BASE_URL` com o endpoint do Azure:
```bash
CODEGRAPHAI_OPENAI_BASE_URL=https://seu-recurso.openai.azure.com/
```

**Refer√™ncia:** [LangChain OpenAI Documentation](https://docs.langchain.com/oss/python/langchain/models)

#### Modo API (Anthropic Claude)

CodeGraphAI suporta Anthropic Claude via API, incluindo o modelo mais recente Claude Sonnet 4.5.

**Configura√ß√£o:**

1. Copie `example.env` para `.env` ou `environment.env` e configure:
```bash
# Copie o template
cp example.env .env
# ou
cp example.env environment.env

# Edite o arquivo com suas credenciais
CODEGRAPHAI_LLM_MODE=api
CODEGRAPHAI_LLM_PROVIDER=anthropic

# Anthropic Claude Configuration
CODEGRAPHAI_ANTHROPIC_API_KEY=sk-ant-...
CODEGRAPHAI_ANTHROPIC_MODEL=claude-sonnet-4-5-20250929
CODEGRAPHAI_ANTHROPIC_TIMEOUT=60
CODEGRAPHAI_ANTHROPIC_TEMPERATURE=0.3
CODEGRAPHAI_ANTHROPIC_MAX_TOKENS=4000
```

2. Use no c√≥digo:
```python
from analyzer import LLMAnalyzer
from config import get_config

config = get_config()
llm = LLMAnalyzer(llm_mode='api', config=config)
```

**Modelo Dispon√≠vel:**
- `claude-sonnet-4-5-20250929`: Claude Sonnet 4.5 (modelo mais recente, padr√£o)
- `claude-sonnet-4-5`: Alias para o modelo mais recente

**Vantagens do Claude Sonnet 4.5:**
- Excelente para an√°lise de c√≥digo e racioc√≠nio complexo
- Suporte a contextos longos
- Alta qualidade em tarefas de an√°lise e extra√ß√£o

**Refer√™ncia:** [LangChain Anthropic Documentation](https://docs.langchain.com/oss/python/langchain/models)

### Quantiza√ß√£o para Economia de Mem√≥ria

Por padr√£o, usa quantiza√ß√£o 8-bit. Para modelos menores:

```python
# Desabilitar quantiza√ß√£o (requer mais VRAM)
# Edite em analyzer.py:
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",
    load_in_8bit=False,  # Altere aqui
    torch_dtype="auto"
)
```

### Ajuste de Prompts

Edite os templates em `LLMAnalyzer._setup_prompts()` para customizar an√°lises:

```python
self.business_logic_prompt = PromptTemplate(
    input_variables=["code", "proc_name"],
    template="""Seu prompt customizado aqui..."""
)
```

## üìà Exemplo de Output

### JSON (analysis.json)

```json
{
  "procedures": {
    "CALC_SALDO": {
      "name": "CALC_SALDO",
      "schema": "FINANCEIRO",
      "complexity_score": 7,
      "dependencies_level": 0,
      "called_procedures": ["VALIDA_CONTA", "BUSCA_HISTORICO"],
      "called_tables": ["CONTAS", "TRANSACOES"],
      "business_logic": "Calcula saldo atual de uma conta..."
    }
  },
  "hierarchy": {
    "0": ["CALC_SALDO", "VALIDA_CONTA"],
    "1": ["GERA_RELATORIO"],
    "2": ["EXPORTA_DADOS"]
  },
  "statistics": {
    "total_procedures": 45,
    "avg_complexity": 5.8,
    "max_dependency_level": 4
  }
}
```

### Mermaid Diagram

```mermaid
graph TD
    CALC_SALDO["CALC_SALDO\n[N√≠vel 0, Complex: 7]"]:::medium
    VALIDA_CONTA["VALIDA_CONTA\n[N√≠vel 0, Complex: 3]"]:::low
    GERA_RELATORIO["GERA_RELATORIO\n[N√≠vel 1, Complex: 9]"]:::high

    GERA_RELATORIO --> CALC_SALDO
    GERA_RELATORIO --> VALIDA_CONTA

    classDef high fill:#ff6b6b,stroke:#c92a2a,color:#fff
    classDef medium fill:#ffd93d,stroke:#f59f00,color:#000
    classDef low fill:#51cf66,stroke:#2b8a3e,color:#000
```

## üíª Comandos CLI

### Comando `analyze`

Analisa tabelas e/ou procedures do banco de dados.

#### Sintaxe B√°sica

```bash
python main.py analyze [OP√á√ïES]
```

#### Argumentos Principais

**Tipo de An√°lise:**
- `--analysis-type [tables|procedures|both]`: Tipo de an√°lise (padr√£o: `both`)
  - `tables`: Analisa apenas tabelas (DDL, relacionamentos, √≠ndices, foreign keys)
  - `procedures`: Analisa apenas stored procedures
  - `both`: Analisa ambos (padr√£o)

**Configura√ß√£o de Banco de Dados:**
- `--db-type [oracle|postgresql|mssql|mysql]`: Tipo de banco (padr√£o: `postgresql`)
- `--user USER`: Usu√°rio do banco de dados
- `--password PASSWORD`: Senha do banco de dados
- `--host HOST`: Host do banco de dados
- `--port PORT`: Porta do banco de dados
- `--database DATABASE`: Nome do banco de dados (obrigat√≥rio para PostgreSQL, SQL Server, MySQL)
- `--dsn DSN`: DSN completo (para Oracle: `host:port/service`)
- `--schema SCHEMA`: Schema espec√≠fico para an√°lise
- `--limit N`: Limite de entidades para an√°lise (opcional)

**Configura√ß√£o LLM:**
- `--model MODEL`: Nome do modelo LLM (sobrescreve config)
- `--device [cuda|cpu]`: Dispositivo para modelos locais (sobrescreve config)

**Exporta√ß√£o:**
- `--export-json`: Exportar JSON (padr√£o: `True`)
- `--export-png`: Exportar grafo PNG (padr√£o: `True`)
- `--export-mermaid`: Exportar diagramas Mermaid (padr√£o: `False`)

**Otimiza√ß√£o (An√°lise de Tabelas):**
- `--batch-size N`: Tamanho do batch para an√°lise de tabelas (padr√£o: `5`, `1` desabilita batch)
- `--parallel-workers N`: N√∫mero de workers paralelos (padr√£o: `2`, `1` desabilita paralelismo)

**Logging:**
- `--log-file PATH`: Arquivo de log espec√≠fico (sobrescreve auto-logging)
- `--no-auto-log`: Desabilita cria√ß√£o autom√°tica de logs
- `--verbose, -v`: Modo verbose (n√≠vel DEBUG)

**Outros:**
- `--output-dir, -o PATH`: Diret√≥rio de sa√≠da (padr√£o: `./output`)
- `--dry-run`: Modo dry-run (valida sem executar)

#### Exemplos Completos

**PostgreSQL - An√°lise de Tabelas:**
```bash
python main.py analyze --analysis-type=tables \
    --db-type postgresql \
    --user postgres \
    --password minha_senha \
    --host localhost \
    --port 5432 \
    --database optomate \
    --schema public \
    --batch-size 5 \
    --parallel-workers 2 \
    --export-json --export-png --export-mermaid
```

**PostgreSQL - An√°lise de Procedures:**
```bash
python main.py analyze --analysis-type=procedures \
    --db-type postgresql \
    --user postgres \
    --password minha_senha \
    --host localhost \
    --port 5432 \
    --database optomate \
    --schema public \
    --limit 50
```

**PostgreSQL - An√°lise Completa (Tabelas + Procedures):**
```bash
python main.py analyze --analysis-type=both \
    --db-type postgresql \
    --user postgres \
    --password minha_senha \
    --host localhost \
    --port 5432 \
    --database optomate \
    --schema public \
    --batch-size 5 \
    --parallel-workers 2 \
    --export-json --export-png --export-mermaid
```

**Oracle - An√°lise de Procedures:**
```bash
python main.py analyze --analysis-type=procedures \
    --db-type oracle \
    --user usuario \
    --password senha \
    --dsn localhost:1521/ORCL \
    --schema MEU_SCHEMA \
    --limit 100
```

**SQL Server - An√°lise de Tabelas:**
```bash
python main.py analyze --analysis-type=tables \
    --db-type mssql \
    --user sa \
    --password senha \
    --host localhost \
    --port 1433 \
    --database meu_banco \
    --schema dbo \
    --batch-size 3 \
    --parallel-workers 1
```

**MySQL - An√°lise Completa:**
```bash
python main.py analyze --analysis-type=both \
    --db-type mysql \
    --user root \
    --password senha \
    --host localhost \
    --port 3306 \
    --database meu_banco \
    --batch-size 5 \
    --parallel-workers 2
```

**Com Logging Customizado:**
```bash
# Usar arquivo de log espec√≠fico
python main.py analyze --analysis-type=tables \
    --db-type postgresql \
    --user postgres --password senha \
    --host localhost --port 5432 \
    --database meu_banco \
    --log-file logs/analise_custom.log

# Desabilitar auto-logging
python main.py --no-auto-log analyze --analysis-type=tables \
    --db-type postgresql \
    --user postgres --password senha \
    --host localhost --port 5432 \
    --database meu_banco

# Modo verbose (DEBUG)
python main.py --verbose analyze --analysis-type=tables \
    --db-type postgresql \
    --user postgres --password senha \
    --host localhost --port 5432 \
    --database meu_banco
```

**Dry-Run (Valida√ß√£o sem Executar):**
```bash
python main.py analyze --analysis-type=tables \
    --db-type postgresql \
    --user postgres --password senha \
    --host localhost --port 5432 \
    --database meu_banco \
    --dry-run
```

**Otimiza√ß√£o de Performance:**
```bash
# Batch processing com paralelismo (recomendado para muitas tabelas)
python main.py analyze --analysis-type=tables \
    --db-type postgresql \
    --user postgres --password senha \
    --host localhost --port 5432 \
    --database meu_banco \
    --batch-size 5 \
    --parallel-workers 2

# Desabilitar batch (processamento sequencial original)
python main.py analyze --analysis-type=tables \
    --db-type postgresql \
    --user postgres --password senha \
    --host localhost --port 5432 \
    --database meu_banco \
    --batch-size 1

# Apenas batch sem paralelismo
python main.py analyze --analysis-type=tables \
    --db-type postgresql \
    --user postgres --password senha \
    --host localhost --port 5432 \
    --database meu_banco \
    --batch-size 5 \
    --parallel-workers 1
```

### Comando `analyze-files`

Analisa procedures a partir de arquivos `.prc` locais.

#### Sintaxe

```bash
python main.py analyze-files [OP√á√ïES]
```

#### Argumentos

- `--directory, -d PATH`: Diret√≥rio com arquivos `.prc` (obrigat√≥rio)
- `--extension, -e EXT`: Extens√£o dos arquivos (padr√£o: `prc`)
- `--output-dir, -o PATH`: Diret√≥rio de sa√≠da (padr√£o: `./output`)
- `--model MODEL`: Nome do modelo LLM (sobrescreve config)
- `--device [cuda|cpu]`: Dispositivo para modelos locais
- `--export-json`: Exportar JSON (padr√£o: `True`)
- `--export-png`: Exportar grafo PNG (padr√£o: `True`)
- `--export-mermaid`: Exportar diagramas Mermaid (padr√£o: `False`)
- `--dry-run`: Modo dry-run (valida sem executar)
- `--log-file PATH`: Arquivo de log espec√≠fico
- `--no-auto-log`: Desabilita cria√ß√£o autom√°tica de logs
- `--verbose, -v`: Modo verbose

#### Exemplos

```bash
# An√°lise b√°sica
python main.py analyze-files --directory ./procedures

# Com extens√£o customizada
python main.py analyze-files --directory ./procedures --extension sql

# Com exporta√ß√£o completa
python main.py analyze-files --directory ./procedures \
    --export-json --export-png --export-mermaid

# Dry-run
python main.py analyze-files --directory ./procedures --dry-run
```

### Comando `test-connection`

Testa conectividade com banco de dados.

#### Sintaxe

```bash
python main.py test-connection [OP√á√ïES]
```

#### Argumentos

- `--db-type [oracle|postgresql|mssql|mysql]`: Tipo de banco
- `--user USER`: Usu√°rio do banco
- `--password PASSWORD`: Senha do banco
- `--host HOST`: Host do banco
- `--port PORT`: Porta do banco
- `--database DATABASE`: Nome do banco (obrigat√≥rio para PostgreSQL, SQL Server, MySQL)
- `--dsn DSN`: DSN completo (para Oracle)
- `--log-file PATH`: Arquivo de log espec√≠fico
- `--no-auto-log`: Desabilita cria√ß√£o autom√°tica de logs
- `--verbose, -v`: Modo verbose

#### Exemplos

```bash
# PostgreSQL
python main.py test-connection --db-type postgresql \
    --user postgres --password senha \
    --host localhost --port 5432 --database meu_banco

# Oracle
python main.py test-connection --db-type oracle \
    --user usuario --password senha \
    --dsn localhost:1521/ORCL
```

### Sistema de Logs Autom√°tico

Por padr√£o, CodeGraphAI cria automaticamente arquivos de log em `logs/` com o formato:
```
logs/{comando}_{timestamp}.log
```

Exemplo: `logs/analyze_20251124_083712.log`

**Configura√ß√£o:**
- Logs s√£o criados automaticamente em `logs/` (configur√°vel via `CODEGRAPHAI_LOG_DIR`)
- Auto-logging pode ser desabilitado via `--no-auto-log` ou `CODEGRAPHAI_AUTO_LOG_ENABLED=false`
- Use `--log-file` para especificar um arquivo espec√≠fico
- Logs capturam tanto output do logging module quanto `click.echo()`

**Vari√°veis de Ambiente:**
```bash
CODEGRAPHAI_LOG_DIR=./logs              # Diret√≥rio para logs
CODEGRAPHAI_AUTO_LOG_ENABLED=true       # Habilitar auto-logging (padr√£o: true)
CODEGRAPHAI_LOG_LEVEL=INFO              # N√≠vel de log (DEBUG, INFO, WARNING, ERROR)
```

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üó∫
